digraph "classes_SMPyBandits.Policies" {
charset="utf-8"
rankdir=BT
"0" [label="{SMPyBandits.Policies.AdBandits.AdBandits|alpha : int\lepsilon\lhorizon : int\lposterior\l|__init__(nbArms, horizon, alpha, posterior, lower, amplitude)\l__str__()\lchoice()\lchoiceWithRank(rank)\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"1" [label="{SMPyBandits.Policies.AdSwitch.AdSwitch|C1 : float\lC2 : float\lall_rewards\lbatch_number : int\lcurrent_best_arm : NoneType\lcurrent_estimated_gap : NoneType\lcurrent_exploitation_arm : int, NoneType\lcurrent_exploration_arm : NoneType, int\lcurrent_worst_arm : NoneType\lhorizon : NoneType\llast_restart_time : int\llast_used_di_pi_si : NoneType, tuple\llength_of_current_phase : NoneType\lphase\lstep_of_current_phase : int\l|__init__(nbArms, horizon, C1, C2)\l__str__()\lchoice()\lcompute_di_pi_si()\lfind_Ik()\lgetReward(arm, reward)\lread_range_of_rewards(arm, start, end)\lstartGame()\lstatistical_test(t, t0)\l}", shape="record"];
"2" [label="{SMPyBandits.Policies.AdSwitchNew.AdSwitchNew|C1 : float\lall_rewards\ldelta_s : int\ldelta_t : int\lell : int\lgap_Delta_tilde_of_l : ndarray\lhistory_of_plays : list\lhorizon : NoneType\lmu_tilde_of_l : ndarray\lset_BAD : set\lset_GOOD : set\lset_S\lstart_of_episode : int\l|__init__(nbArms, horizon, C1, delta_s, delta_t)\l__str__()\lcheck_changes_bad_arms()\lcheck_changes_good_arms()\lchoice()\lfind_max_i(gap)\lgetReward(arm, reward)\lmu_hat_s_t(arm, s, t)\ln_s_t(arm, s, t)\lnew_episode()\lstartGame()\l}", shape="record"];
"3" [label="{SMPyBandits.Policies.Aggregator.Aggregator|amplitude : float\lchildren : list\lchildren_cumulated_losses : ndarray\lchoices\ldecreaseRate : str, NoneType\lextra_str : str\lhorizon : int, NoneType\lindex : ndarray\llearningRate : NoneType\llower : float\lnbArms\lnbChildren\lrate\lt : int\ltrusts : str\lunbiased : bool\lupdate_all_children : bool\lupdate_like_exp4 : bool\l|__init__(nbArms, children, learningRate, decreaseRate, horizon, update_all_children, update_like_exp4, unbiased, prior, lower, amplitude, extra_str)\l__str__()\l_makeChildrenChoose()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceIMP(nb, startWithChoiceMultiple)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lcomputeAllIndex()\lcomputeIndex(arm)\lestimatedBestArms(M)\lestimatedOrder()\lgetReward(arm, reward)\lhandleCollision(arm, reward)\lstartGame()\l}", shape="record"];
"4" [label="{SMPyBandits.Policies.ApproximatedFHGittins.ApproximatedFHGittins|alpha : float\ldistortion_horizon : float\lhorizon : int\lm\l|__init__(nbArms, horizon, alpha, distortion_horizon, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"5" [label="{SMPyBandits.Policies.BESA.BESA|_actions\l_besa_function\l_has_horizon\l_left : int\l_right\l_subsample_function\lall_rewards : ndarray\lhorizon : NoneType\lindex\lminPullsOfEachArm\lnon_binary : bool\lnon_recursive : bool\lrandom_subsample : bool\lrandomized_tournament : bool\l|__init__(nbArms, horizon, minPullsOfEachArm, randomized_tournament, random_subsample, non_binary, non_recursive, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lcomputeAllIndex()\lcomputeIndex(arm)\lgetReward(arm, reward)\lhandleCollision(arm, reward)\l}", shape="record"];
"6" [label="{SMPyBandits.Policies.BasePolicy.BasePolicy|amplitude : float\llower : float\lnbArms\lpulls : ndarray\lrewards : ndarray\lt : int\l|__init__(nbArms, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceIMP(nb, startWithChoiceMultiple)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lestimatedOrder()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"7" [label="{SMPyBandits.Policies.BaseWrapperPolicy.BaseWrapperPolicy|_args : tuple\l_kwargs : dict\l_policy\lindex\lpolicy : NoneType\l|__init__(nbArms, policy)\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceIMP(nb, startWithChoiceMultiple)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lcomputeAllIndex()\lcomputeIndex(arm)\lestimatedBestArms(M)\lestimatedOrder()\lgetReward(arm, reward)\lstartGame(createNewPolicy)\l}", shape="record"];
"8" [label="{SMPyBandits.Policies.BayesUCB.BayesUCB|\l|computeIndex(arm)\l}", shape="record"];
"9" [label="{SMPyBandits.Policies.BayesianIndexPolicy.BayesianIndexPolicy|_posterior_name : str\lposterior\lt : int\l|__init__(nbArms, posterior, lower, amplitude)\l__str__()\lcomputeIndex(arm)\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"10" [label="{SMPyBandits.Policies.BoltzmannGumbel.BoltzmannGumbel|C : int\l|__init__(nbArms, C, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"11" [label="{SMPyBandits.Policies.CD_UCB.CD_IndexPolicy|_full_restart_when_refresh : bool\l_per_arm_restart : bool\lall_rewards\lepsilon : float\llast_pulls : ndarray\llast_restart_times : ndarray\llazy_detect_change_only_x_steps : int\lnumber_of_restart : int\lproba_random_exploration\l|__init__(nbArms, full_restart_when_refresh, per_arm_restart, epsilon, proba_random_exploration, lazy_detect_change_only_x_steps)\l__str__()\lchoice()\lchoiceWithRank(rank)\ldetect_change(arm, verbose)\lgetReward(arm, reward)\l}", shape="record"];
"12" [label="{SMPyBandits.Policies.CD_UCB.SlidingWindowRestart_IndexPolicy|\l|detect_change(arm, verbose)\l}", shape="record"];
"13" [label="{SMPyBandits.Policies.CD_UCB.UCBLCB_IndexPolicy|_delta : NoneType\l_delta0 : float\llazy_try_value_s_only_x_steps : int\lproba_random_exploration : int\luse_localization : bool\l|__init__(nbArms, delta, delta0, lazy_try_value_s_only_x_steps, use_localization)\l__str__()\ldelta(t)\ldetect_change(arm, verbose)\l}", shape="record"];
"14" [label="{SMPyBandits.Policies.CORRAL.CORRAL|_default_parameters : bool\lamplitude : float\lbar_trusts\lbeta\lbroadcast_all : bool\lchildren : list\lchoices\lgamma\llast_choice : NoneType\llosses : ndarray\llower : float\lnbArms\lnbChildren\lrates\lrhos\ltrusts : str\lunbiased : bool\l|__init__(nbArms, children, horizon, rate, unbiased, broadcast_all, prior, lower, amplitude)\l__setattr__(name, value)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceIMP(nb, startWithChoiceMultiple)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lestimatedBestArms(M)\lestimatedOrder()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"15" [label="{SMPyBandits.Policies.CPUCB.CPUCB|c : float\l|__init__(nbArms, c, lower, amplitude)\lcomputeIndex(arm)\l}", shape="record"];
"16" [label="{SMPyBandits.Policies.CUSUM_UCB.CUSUM_IndexPolicy|M : int\lmax_nb_random_events : NoneType\lproba_random_exploration\lthreshold_h : ndarray\luse_localization : bool\l|__init__(nbArms, horizon, max_nb_random_events, lmbda, min_number_of_observation_between_change_point, full_restart_when_refresh, per_arm_restart, use_localization)\l__str__()\ldetect_change(arm, verbose)\lgetReward(arm, reward)\l}", shape="record"];
"17" [label="{SMPyBandits.Policies.CUSUM_UCB.PHT_IndexPolicy|\l|__str__()\ldetect_change(arm, verbose)\l}", shape="record"];
"18" [label="{SMPyBandits.Policies.DMED.DMED|genuine : bool\lkl : vectorize\lnextActions : list\ltolerance : float\l|__init__(nbArms, genuine, tolerance, kl, lower, amplitude)\l__str__()\lchoice()\lchoiceMultiple(nb)\lstartGame()\l}", shape="record"];
"19" [label="{SMPyBandits.Policies.DMED.DMEDPlus|\l|__init__(nbArms, tolerance, kl, lower, amplitude)\l}", shape="record"];
"20" [label="{SMPyBandits.Policies.DiscountedBayesianIndexPolicy.DiscountedBayesianIndexPolicy|gamma : float\lt\l|__init__(nbArms, gamma, posterior, lower, amplitude)\l__str__()\lgetReward(arm, reward)\l}", shape="record"];
"21" [label="{SMPyBandits.Policies.DiscountedThompson.DiscountedThompson|\l|computeIndex(arm)\l}", shape="record"];
"22" [label="{SMPyBandits.Policies.DiscountedUCB.DiscountedUCB|alpha : int\ldelta_time_steps : ndarray\ldiscounted_pulls : ndarray\ldiscounted_rewards : ndarray\lgamma : float\luseRealDiscount : bool\l|__init__(nbArms, alpha, gamma, useRealDiscount)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\lgetReward(arm, reward)\l}", shape="record"];
"23" [label="{SMPyBandits.Policies.DiscountedUCB.DiscountedUCBPlus|\l|__init__(nbArms, horizon, max_nb_random_events, alpha)\l}", shape="record"];
"24" [label="{SMPyBandits.Policies.DiscountedUCB.DiscountedklUCB|klucb\l|__init__(nbArms, klucb)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"25" [label="{SMPyBandits.Policies.DiscountedUCB.DiscountedklUCBPlus|\l|__str__()\l}", shape="record"];
"26" [label="{SMPyBandits.Policies.DoublingTrickWrapper.DoublingTrickWrapper|_first_horizon\l_i : int\l_next_horizon\lfull_restart : bool\lhorizon : int\lnext_horizon_name : str\lpolicy\lt\l|__init__(nbArms, full_restart, policy, next_horizon, first_horizon)\l__str__()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"27" [label="{SMPyBandits.Policies.EmpiricalMeans.EmpiricalMeans|\l|computeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"28" [label="{SMPyBandits.Policies.EpsilonGreedy.EpsilonDecreasing|_epsilon : float\lepsilon\l|__init__(nbArms, epsilon, lower, amplitude)\l__str__()\l}", shape="record"];
"29" [label="{SMPyBandits.Policies.EpsilonGreedy.EpsilonDecreasingMEGA|_epsilon\lepsilon\l|__init__(nbArms, c, d, lower, amplitude)\l__str__()\l}", shape="record"];
"30" [label="{SMPyBandits.Policies.EpsilonGreedy.EpsilonExpDecreasing|_decreasingRate : float\l_epsilon : float\lepsilon\l|__init__(nbArms, epsilon, decreasingRate, lower, amplitude)\l__str__()\l}", shape="record"];
"31" [label="{SMPyBandits.Policies.EpsilonGreedy.EpsilonFirst|_epsilon : float\lepsilon\lhorizon : int\l|__init__(nbArms, horizon, epsilon, lower, amplitude)\l__str__()\l}", shape="record"];
"32" [label="{SMPyBandits.Policies.EpsilonGreedy.EpsilonGreedy|_epsilon : float\lepsilon\l|__init__(nbArms, epsilon, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\l}", shape="record"];
"33" [label="{SMPyBandits.Policies.Exp3.Exp3|_gamma : float\l_initial_exploration\lgamma\ltrusts\lunbiased : bool\lweights\l|__init__(nbArms, gamma, unbiased, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lestimatedBestArms(M)\lestimatedOrder()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"34" [label="{SMPyBandits.Policies.Exp3.Exp3Decreasing|gamma\l|__str__()\l}", shape="record"];
"35" [label="{SMPyBandits.Policies.Exp3.Exp3ELM|B\lavailableArms\ldelta : float\lgamma\lt\ltrusts\lvarianceTerm : ndarray\l|__init__(nbArms, delta, unbiased, lower, amplitude)\l__str__()\lchoice()\lgetReward(arm, reward)\l}", shape="record"];
"36" [label="{SMPyBandits.Policies.Exp3.Exp3SoftMix|gamma\l|__str__()\l}", shape="record"];
"37" [label="{SMPyBandits.Policies.Exp3.Exp3WithHorizon|gamma\lhorizon : int\l|__init__(nbArms, horizon, unbiased, lower, amplitude)\l__str__()\l}", shape="record"];
"38" [label="{SMPyBandits.Policies.Exp3PlusPlus.Exp3PlusPlus|_initial_exploration\lalpha : int\lbeta : int\lepsilon\leta\lgamma\lgap_estimate\llosses : ndarray\ltrusts\lunweighted_losses : ndarray\lweights\lxi\l|__init__(nbArms, alpha, beta, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lestimatedBestArms(M)\lestimatedOrder()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"39" [label="{SMPyBandits.Policies.Exp3R.DriftDetection_IndexPolicy|H : int, NoneType\ldelta : NoneType\lhorizon : NoneType\lmin_number_of_pulls_to_test_change\lproba_random_exploration\lthreshold_h\l|__init__(nbArms, H, delta, C, horizon, policy)\l__str__()\ldetect_change(arm, verbose)\l}", shape="record"];
"40" [label="{SMPyBandits.Policies.Exp3R.Exp3R|\l|__init__(nbArms, policy)\l__str__()\l}", shape="record"];
"41" [label="{SMPyBandits.Policies.Exp3R.Exp3RPlusPlus|\l|__init__(nbArms, policy)\l__str__()\l}", shape="record"];
"42" [label="{SMPyBandits.Policies.Exp3S.Exp3S|_alpha : NoneType, float\l_gamma : NoneType, float\lalpha\lgamma\lhorizon : NoneType, str\lmax_nb_random_events : NoneType, str\lt\ltrusts\lweights\l|__init__(nbArms, gamma, alpha, gamma0, alpha0, horizon, max_nb_random_events)\l__str__()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"43" [label="{SMPyBandits.Policies.ExploreThenCommit.DeltaUCB|alpha : int\lepsilon_T\lgap : float\lhorizon : int\l|__init__(nbArms, horizon, gap, alpha, lower, amplitude)\l__str__()\lchoice()\l}", shape="record"];
"44" [label="{SMPyBandits.Policies.ExploreThenCommit.ETC_BAI|alpha : int\l|__init__(nbArms, horizon, alpha, lower, amplitude)\lstopping_criteria()\l}", shape="record"];
"45" [label="{SMPyBandits.Policies.ExploreThenCommit.ETC_FixedBudget|best_identified_arm : NoneType\lepsilon\lgap : float\lhorizon : int\lmax_t\lround_robin_index : int\l|__init__(nbArms, horizon, gap, lower, amplitude)\l__str__()\lchoice()\l}", shape="record"];
"46" [label="{SMPyBandits.Policies.ExploreThenCommit.ETC_KnownGap|epsilon\lgap : float\lhorizon : int\lmax_t\l|__init__(nbArms, horizon, gap, lower, amplitude)\l__str__()\l}", shape="record"];
"47" [label="{SMPyBandits.Policies.ExploreThenCommit.ETC_RandomStop|alpha : int\lepsilon\lhorizon : int\lstillRandom : bool\l|__init__(nbArms, horizon, alpha, lower, amplitude)\l__str__()\l}", shape="record"];
"48" [label="{SMPyBandits.Policies.ExploreThenCommit.ETC_SPRT|\l|stopping_criteria()\l}", shape="record"];
"49" [label="{SMPyBandits.Policies.ExploreThenCommit._ETC_RoundRobin_WithStoppingCriteria|best_identified_arm : NoneType\lepsilon\lgap : float\lhorizon : int\lround_robin_index : int\l|__init__(nbArms, horizon, gap, lower, amplitude)\l__str__()\lchoice()\lstopping_criteria()\l}", shape="record"];
"50" [label="{SMPyBandits.Policies.FEWA.EFF_FEWA|alpha : float\larmSet\ldelta : NoneType, int\ldisplay_m\lgrid : NoneType, int\linlogconst : int\lnbArms\loutlogconst : tuple, list\lstatistics : tuple, list\lsubgaussian : int\lwindows : tuple, ndarray, list\l|__init__(nbArms, alpha, subgaussian, m, delta)\l__str__()\l_append_thresholds(w)\l_inlog()\lchoice()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"51" [label="{SMPyBandits.Policies.FEWA.FEWA|\l|__init__(nbArms, subgaussian, alpha, delta)\l__str__()\l}", shape="record"];
"52" [label="{SMPyBandits.Policies.GLR_UCB.BernoulliGLR_IndexPolicy|\l|__init__(nbArms, kl, threshold_function)\l}", shape="record"];
"53" [label="{SMPyBandits.Policies.GLR_UCB.BernoulliGLR_IndexPolicy_WithDeterministicExploration|\l|}", shape="record"];
"54" [label="{SMPyBandits.Policies.GLR_UCB.BernoulliGLR_IndexPolicy_WithTracking|\l|}", shape="record"];
"55" [label="{SMPyBandits.Policies.GLR_UCB.GLR_IndexPolicy|_alpha0 : NoneType, float\l_alpha_t1 : float\l_args_to_kl : tuple\l_exponentBeta : float\l_threshold_function\l_use_increasing_alpha : bool\l_variant : NoneType\ldelta : NoneType, float\lhorizon : NoneType\lkl\llazy_try_value_s_only_x_steps : int\lmax_nb_random_events : NoneType\lproba_random_exploration\luse_localization : bool\l|__init__(nbArms, horizon, delta, max_nb_random_events, kl, alpha0, exponentBeta, alpha_t1, threshold_function, variant, use_increasing_alpha, lazy_try_value_s_only_x_steps, per_arm_restart, use_localization)\l__str__()\lcompute_threshold_h(t)\ldetect_change(arm, verbose)\lgetReward(arm, reward)\l}", shape="record"];
"56" [label="{SMPyBandits.Policies.GLR_UCB.GLR_IndexPolicy_WithDeterministicExploration|\l|choice()\l}", shape="record"];
"57" [label="{SMPyBandits.Policies.GLR_UCB.GLR_IndexPolicy_WithTracking|\l|choice()\l}", shape="record"];
"58" [label="{SMPyBandits.Policies.GLR_UCB.GaussianGLR_IndexPolicy|_args_to_kl : tuple\l_sig2 : float\l|__init__(nbArms, sig2, kl, threshold_function)\l}", shape="record"];
"59" [label="{SMPyBandits.Policies.GLR_UCB.GaussianGLR_IndexPolicy_WithDeterministicExploration|\l|}", shape="record"];
"60" [label="{SMPyBandits.Policies.GLR_UCB.GaussianGLR_IndexPolicy_WithTracking|\l|}", shape="record"];
"61" [label="{SMPyBandits.Policies.GLR_UCB.OurGaussianGLR_IndexPolicy|_args_to_kl : tuple\l_sig2 : float\l|__init__(nbArms, sig2, kl, threshold_function)\l}", shape="record"];
"62" [label="{SMPyBandits.Policies.GLR_UCB.OurGaussianGLR_IndexPolicy_WithDeterministicExploration|\l|}", shape="record"];
"63" [label="{SMPyBandits.Policies.GLR_UCB.OurGaussianGLR_IndexPolicy_WithTracking|\l|}", shape="record"];
"64" [label="{SMPyBandits.Policies.GLR_UCB.SubGaussianGLR_IndexPolicy|_alpha0 : NoneType, int\l_alpha_t1 : float\l_exponentBeta : float\ldelta : float\lhorizon : NoneType\ljoint : bool\llazy_try_value_s_only_x_steps : int\lmax_nb_random_events : NoneType\lproba_random_exploration\lsigma : float\luse_localization : bool\l|__init__(nbArms, horizon, max_nb_random_events, full_restart_when_refresh, policy, delta, sigma, joint, exponentBeta, alpha_t1, alpha0, lazy_detect_change_only_x_steps, lazy_try_value_s_only_x_steps, use_localization)\l__str__()\lcompute_threshold_h(s, t)\ldetect_change(arm, verbose)\l}", shape="record"];
"65" [label="{SMPyBandits.Policies.GenericAggregation.GenericAggregation|amplitude : float\lchildren : list\llast_choice : int\llower : float\lmaster : NoneType\lnbArms\lnbChildren\l|__init__(nbArms, master, children, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceIMP(nb, startWithChoiceMultiple)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lestimatedBestArms(M)\lestimatedOrder()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"66" [label="{SMPyBandits.Policies.GreedyOracle.GreedyOracle|arms\l|__init__(nbArms, arms)\lcomputeIndex(arm)\l}", shape="record"];
"67" [label="{SMPyBandits.Policies.GreedyOracle.GreedyPolicy|last_pull\l|__init__(nbArms)\lcomputeAllIndex()\lcomputeIndex(arm)\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"68" [label="{SMPyBandits.Policies.Hedge.Hedge|_epsilon : float\l_initial_exploration\lepsilon\ltrusts\lweights\l|__init__(nbArms, epsilon, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lestimatedBestArms(M)\lestimatedOrder()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"69" [label="{SMPyBandits.Policies.Hedge.HedgeDecreasing|epsilon\l|__str__()\l}", shape="record"];
"70" [label="{SMPyBandits.Policies.Hedge.HedgeWithHorizon|epsilon\lhorizon : int\l|__init__(nbArms, horizon, lower, amplitude)\l__str__()\l}", shape="record"];
"71" [label="{SMPyBandits.Policies.IMED.IMED|\l|Dinf(xs, mu)\l__init__(nbArms, tolerance, kl, lower, amplitude)\l__str__()\lchoice()\lone_Dinf(x, mu)\l}", shape="record"];
"72" [label="{SMPyBandits.Policies.IndexPolicy.IndexPolicy|index : ndarray\l|__init__(nbArms, lower, amplitude)\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceIMP(nb, startWithChoiceMultiple)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lcomputeAllIndex()\lcomputeIndex(arm)\lestimatedBestArms(M)\lestimatedOrder()\lstartGame()\l}", shape="record"];
"73" [label="{SMPyBandits.Policies.LM_DSEE.LM_DSEE|a : int\lall_rewards\lb : float\lbatch_number : int\lcurrent_exploitation_arm : NoneType\lcurrent_exploration_arm : int, NoneType\lgamma : float\ll : int\llength_of_current_phase : NoneType\lphase\lrho\lstep_of_current_phase : int\l|__init__(nbArms, nu, DeltaMin, a, b)\l__str__()\lchoice()\lgetReward(arm, reward)\llength_exploitation_phase(verbose)\llength_exploration_phase(verbose)\lstartGame()\l}", shape="record"];
"74" [label="{SMPyBandits.Policies.LearnExp.LearnExp|amplitude : float\lchildren : list\leta : float\llast_choice : NoneType\llower : float\lnbArms\lnbChildren\lrate\ltrusts : str\lunbiased : bool\lweights\l|__init__(nbArms, children, unbiased, eta, prior, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceIMP(nb, startWithChoiceMultiple)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lestimatedBestArms(M)\lestimatedOrder()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"75" [label="{SMPyBandits.Policies.MEGA.MEGA|alpha : float\lbeta : float\lc : float\lchosenArm : ndarray, NoneType\ld : float\lmeanRewards : ndarray\lp : float\lp0 : float\lt\ltnext : ndarray\l|__init__(nbArms, p0, alpha, beta, c, d, lower, amplitude)\l__str__()\l_epsilon_t()\lchoice()\lgetReward(arm, reward)\lhandleCollision(arm, reward)\lstartGame()\l}", shape="record"];
"76" [label="{SMPyBandits.Policies.MOSS.MOSS|\l|computeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"77" [label="{SMPyBandits.Policies.MOSSAnytime.MOSSAnytime|alpha : float\l|__init__(nbArms, alpha, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"78" [label="{SMPyBandits.Policies.MOSSExperimental.MOSSExperimental|\l|__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"79" [label="{SMPyBandits.Policies.MOSSH.MOSSH|horizon : int\l|__init__(nbArms, horizon, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"80" [label="{SMPyBandits.Policies.Monitored_UCB.Monitored_IndexPolicy|_full_restart_when_refresh : bool\l_per_arm_restart : bool\lgamma\llast_pulls : ndarray\llast_restart_times : ndarray\llast_update_time_tau : int\llast_w_rewards\lthreshold_b : NoneType\lwindow_size : int, NoneType\l|__init__(nbArms, full_restart_when_refresh, per_arm_restart, horizon, delta, max_nb_random_events, w, b, gamma)\l__str__()\lchoice()\lchoiceWithRank(rank)\ldetect_change(arm)\lgetReward(arm, reward)\l}", shape="record"];
"81" [label="{SMPyBandits.Policies.MusicalChair.MusicalChair|A\lTime0 : int, float\lchair : NoneType\lcumulatedRewards : ndarray\lnbCollision : int\lnbObservations : ndarray\lnbPlayers : int, NoneType\lstate\lt : int\l|__init__(nbArms, Time0, Time1, N, lower, amplitude)\l__str__()\l_endInitialPhase()\lchoice()\lgetReward(arm, reward)\lhandleCollision(arm, reward)\lstartGame()\l}", shape="record"];
"82" [label="{SMPyBandits.Policies.MusicalChairNoSensing.MusicalChairNoSensing|A\lchair : NoneType\lconstant_c : int\lconstant_g\lconstant_in_testing_the_gap\lcumulatedRewards : ndarray\lhorizon : int\lnbArms : int\lnbObservations : ndarray\lnbPlayers : int\lstate\lt : int\ltau_phase_2 : int\l|__init__(nbPlayers, nbArms, horizon, constant_c, lower, amplitude)\l__str__()\l_endPhase2()\lchoice()\lgetReward(arm, reward)\lhandleCollision(arm, reward)\lstartGame()\l}", shape="record"];
"83" [label="{SMPyBandits.Policies.OCUCB.OCUCB|eta : int\lrho : int\l|_Bterm(k)\l_Bterms()\l__init__(nbArms, eta, rho, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"84" [label="{SMPyBandits.Policies.OCUCBH.AOCUCBH|\l|__init__(nbArms, horizon, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"85" [label="{SMPyBandits.Policies.OCUCBH.OCUCBH|alpha : int\lhorizon : int\lpsi : int\l|__init__(nbArms, horizon, psi, alpha, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"86" [label="{SMPyBandits.Policies.OSSB.GaussianOSSB|\l|__init__(nbArms, epsilon, gamma, variance, lower, amplitude)\l}", shape="record"];
"87" [label="{SMPyBandits.Policies.OSSB.OSSB|_info_on_solver : str\l_kwargs : dict\l_solve_optimization_problem\lcounter_s_no_exploitation_phase : int\lepsilon : float\lgamma : float\lphase : NoneType\l|__init__(nbArms, epsilon, gamma, solve_optimization_problem, lower, amplitude)\l__str__()\lchoice()\lgetReward(arm, reward)\lhandleCollision(arm, reward)\lstartGame()\l}", shape="record"];
"88" [label="{SMPyBandits.Policies.OSSB.OSSB_AutoDecreasingRate|epsilon\lgamma\l|__init__(nbArms, lower, amplitude)\l__str__()\l}", shape="record"];
"89" [label="{SMPyBandits.Policies.OSSB.OSSB_DecreasingRate|_decreasingRate : float\l_epsilon : float\l_gamma : float\lepsilon\lgamma\l|__init__(nbArms, epsilon, gamma, decreasingRate, lower, amplitude)\l__str__()\l}", shape="record"];
"90" [label="{SMPyBandits.Policies.OSSB.SparseOSSB|_info_on_solver\l|__init__(nbArms, epsilon, gamma, sparsity, lower, amplitude)\l}", shape="record"];
"91" [label="{SMPyBandits.Policies.OracleSequentiallyRestartPolicy.OracleSequentiallyRestartPolicy|_full_restart_when_refresh : bool\l_per_arm_restart : bool\lall_rewards\lchangePoints\llast_pulls : ndarray\lreset_for_all_change : bool\lreset_for_suboptimal_change : bool\l|__init__(nbArms, changePoints, listOfMeans, reset_for_all_change, reset_for_suboptimal_change, full_restart_when_refresh, per_arm_restart)\l__str__()\lcompute_optimized_changePoints(changePoints, listOfMeans)\ldetect_change(arm)\lgetReward(arm, reward)\l}", shape="record"];
"92" [label="{SMPyBandits.Policies.PHE.PHE|perturbation_scale : float\l|__init__(nbArms, perturbation_scale, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"93" [label="{SMPyBandits.Policies.ProbabilityPursuit.ProbabilityPursuit|_beta : float\l_prior : str\lbeta\lprobabilities : str\l|__init__(nbArms, beta, prior, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"94" [label="{SMPyBandits.Policies.RAWUCB.EFF_RAWUCB|ucb\l|__str__()\l_append_thresholds(w)\l_compute_ucb()\lchoice()\l}", shape="record"];
"95" [label="{SMPyBandits.Policies.RAWUCB.EFF_RAWUCB_asymptotic|beta : int\l|__init__(nbArms, subgaussian, beta, m)\l__str__()\l_inlog()\l}", shape="record"];
"96" [label="{SMPyBandits.Policies.RAWUCB.EFF_RAWklUCB|c : int\lklucb_vec : vectorize\ltolerance : float\lucb : tuple\l|__init__(nbArms, subgaussian, alpha, klucb, tol, m)\l__str__()\lchoice()\l}", shape="record"];
"97" [label="{SMPyBandits.Policies.RAWUCB.RAWUCB|\l|__init__(nbArms, subgaussian, alpha)\l__str__()\l}", shape="record"];
"98" [label="{SMPyBandits.Policies.RCB.RCB|\l|}", shape="record"];
"99" [label="{SMPyBandits.Policies.RandomizedIndexPolicy.RandomizedIndexPolicy|index\lperturbation : str\lperturbation_name : str\l|__init__(nbArms, perturbation, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"100" [label="{SMPyBandits.Policies.SIC_MMAB.SIC_MMAB|Time0 : int\l_nbArms\lactive_arms\lalpha : float\lext_rank : int\lhorizon\lint_rank : int\llast_action : int, ndarray\llast_phase_stats : ndarray\lnbArms\lnbPlayers : int\lphase\lround_number : int\lt\lt_phase : int\lverbose : bool\l|__init__(nbArms, horizon, lower, amplitude, alpha, verbose)\l__str__()\lchoice()\lcompute_ucb_lcb()\lgetReward(arm, reward, collision)\lhandleCollision(arm, reward)\lstartGame()\l}", shape="record"];
"101" [label="{SMPyBandits.Policies.SIC_MMAB.SIC_MMAB_UCB|\l|__str__()\lcompute_ucb_lcb()\l}", shape="record"];
"102" [label="{SMPyBandits.Policies.SIC_MMAB.SIC_MMAB_klUCB|c : float\lklucb : vectorize\ltolerance : float\l|__init__(nbArms, horizon, lower, amplitude, alpha, verbose, tolerance, klucb, c)\l__str__()\lcompute_ucb_lcb()\l}", shape="record"];
"103" [label="{SMPyBandits.Policies.SWA.SWA|alpha : float\larmSet : set\larms_history\ldoubling : bool\lh\lhorizon : int\lnbArms\lstarting_horizon : int\lsubgaussian : int\lt : int\l|__init__(nbArms, horizon, subgaussian, maxDecrement, alpha, doublingTrick)\lcomputeIndex(arm)\lgetReward(arm, reward)\lsetWindow()\lstartGame(resetHorizon)\l}", shape="record"];
"104" [label="{SMPyBandits.Policies.SWA.wSWA|h\lhorizon\l|__init__(nbArms, firstHorizon, subgaussian, maxDecrement, alpha)\l__str__()\ldoublingTrick()\lgetReward(arm, reward)\l}", shape="record"];
"105" [label="{SMPyBandits.Policies.SWHash_UCB.SWHash_IndexPolicy|all_pulls : list\lall_rewards : list\lalpha : float\llmbda : int\lt\ltau\l|__init__(nbArms, policy, alpha, lmbda, lower, amplitude)\l__str__()\lgetReward(arm, reward)\lstartGame(createNewPolicy)\l}", shape="record"];
"106" [label="{SMPyBandits.Policies.SlidingWindowRestart.SWR_UCB|full_restart_when_refresh : bool\llast_pulls : ndarray\llast_rewards : ndarray\ltau : int\lthreshold : float\l|__init__(nbArms, tau, threshold, full_restart_when_refresh)\l__str__()\lgetReward(arm, reward)\l}", shape="record"];
"107" [label="{SMPyBandits.Policies.SlidingWindowRestart.SWR_UCBalpha|full_restart_when_refresh : bool\llast_pulls : ndarray\llast_rewards : ndarray\ltau : int\lthreshold : float\l|__init__(nbArms, tau, threshold, full_restart_when_refresh, alpha)\l__str__()\lgetReward(arm, reward)\l}", shape="record"];
"108" [label="{SMPyBandits.Policies.SlidingWindowRestart.SWR_klUCB|full_restart_when_refresh : bool\llast_pulls : ndarray\llast_rewards : ndarray\ltau : int\lthreshold : float\l|__init__(nbArms, tau, threshold, full_restart_when_refresh, tolerance, klucb, c)\l__str__()\lgetReward(arm, reward)\l}", shape="record"];
"109" [label="{SMPyBandits.Policies.SlidingWindowRestart.SlidingWindowRestart|_full_restart_when_refresh : bool\l_tau : int\l_threshold : float\llast_pulls : ndarray\llast_rewards : ndarray\l|__init__(nbArms, policy, tau, threshold, full_restart_when_refresh)\l__str__()\lgetReward(arm, reward)\l}", shape="record"];
"110" [label="{SMPyBandits.Policies.SlidingWindowUCB.SWUCB|alpha : float\llast_choices\llast_rewards : ndarray\lt\ltau : int\l|__init__(nbArms, tau, alpha)\l__str__()\lcomputeIndex(arm)\lgetReward(arm, reward)\l}", shape="record"];
"111" [label="{SMPyBandits.Policies.SlidingWindowUCB.SWUCBPlus|\l|__init__(nbArms, horizon)\l__str__()\l}", shape="record"];
"112" [label="{SMPyBandits.Policies.SlidingWindowUCB.SWklUCB|klucb\l|__init__(nbArms, tau, klucb)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"113" [label="{SMPyBandits.Policies.SlidingWindowUCB.SWklUCBPlus|\l|__str__()\l}", shape="record"];
"114" [label="{SMPyBandits.Policies.Softmax.SoftMix|temperature\l|__str__()\l}", shape="record"];
"115" [label="{SMPyBandits.Policies.Softmax.Softmax|_initial_exploration\l_temperature : NoneType\ltemperature\ltrusts\lunbiased : bool\l|__init__(nbArms, temperature, unbiased, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lestimatedOrder()\lstartGame()\l}", shape="record"];
"116" [label="{SMPyBandits.Policies.Softmax.SoftmaxDecreasing|temperature\l|__str__()\l}", shape="record"];
"117" [label="{SMPyBandits.Policies.Softmax.SoftmaxWithHorizon|horizon : int\ltemperature\l|__init__(nbArms, horizon, lower, amplitude)\l__str__()\l}", shape="record"];
"118" [label="{SMPyBandits.Policies.SparseUCB.SparseUCB|force_to_see\lgoods\loffset : int\lphase\lsparsity : NoneType\l|__init__(nbArms, sparsity, alpha, lower, amplitude)\l__str__()\lchoice()\lstartGame()\lupdate_j()\lupdate_k()\l}", shape="record"];
"119" [label="{SMPyBandits.Policies.SparseWrapper.SparseWrapper|alpha : int\lforce_to_see\lgoods\loffset : int\lphase\lsparsity : NoneType\luse_ucb_for_set_J : bool\luse_ucb_for_set_K : bool\l|__init__(nbArms, sparsity, use_ucb_for_set_K, use_ucb_for_set_J, alpha, policy, lower, amplitude)\l__str__()\lchoice()\lstartGame()\lupdate_j()\lupdate_k()\l}", shape="record"];
"120" [label="{SMPyBandits.Policies.SparseklUCB.SparseklUCB|force_to_see\lgoods\loffset : int\lphase\lsparsity : NoneType\luse_ucb_for_sets : bool\l|__init__(nbArms, sparsity, tolerance, klucb, c, use_ucb_for_sets, lower, amplitude)\l__str__()\lchoice()\lstartGame()\lupdate_j()\lupdate_k()\l}", shape="record"];
"121" [label="{SMPyBandits.Policies.SuccessiveElimination.SuccessiveElimination|\l|choice()\l}", shape="record"];
"122" [label="{SMPyBandits.Policies.TakeFixedArm.TakeFixedArm|armIndex : int, NoneType\lnbArms\l|__init__(nbArms, armIndex, lower, amplitude)\l__str__()\lchoice()\lchoiceWithRank(rank)\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"123" [label="{SMPyBandits.Policies.TakeRandomFixedArm.TakeRandomFixedArm|armIndexes : list\lnbArms\l|__init__(nbArms, lower, amplitude, nbArmIndexes)\l__str__()\lchoice()\l}", shape="record"];
"124" [label="{SMPyBandits.Policies.Thompson.Thompson|\l|__str__()\lcomputeIndex(arm)\l}", shape="record"];
"125" [label="{SMPyBandits.Policies.TrekkingTSN.TrekkingTSN|J : NoneType, int, ndarray\lM : ndarray\lT_CC\lT_RH : int\lT_SH : int\lT_TR : int\lY : ndarray\lcumulatedRewards : ndarray\ldelta : float\lepsilon : float\lindex_sort : NoneType\llast_choice : NoneType, ndarray, int\llast_was_successful : bool\llock_channel : bool\lnbObservations : ndarray\lstate\lt : int\ltheta : float\l|__init__(nbArms, theta, epsilon, delta, lower, amplitude)\l__str__()\l_endCCPhase()\lchoice()\lgetReward(arm, reward)\lhandleCollision(arm, reward)\lstartGame()\l}", shape="record"];
"126" [label="{SMPyBandits.Policies.TsallisInf.TsallisInf|alpha : float\lcumulative_losses : ndarray\leta\linverse_exponent : float\ltrusts\lweights\l|__init__(nbArms, alpha, lower, amplitude)\l__str__()\lgetReward(arm, reward)\l}", shape="record"];
"127" [label="{SMPyBandits.Policies.UCB.UCB|amplitude\lgamma\lhorizon\llower\lt : ndarray\lt_for_each_arm\l|computeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"128" [label="{SMPyBandits.Policies.UCBH.UCBH|alpha : int\lhorizon : int\l|__init__(nbArms, horizon, alpha, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"129" [label="{SMPyBandits.Policies.UCBV.UCBV|rewardsSquared : ndarray\l|__init__(nbArms, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"130" [label="{SMPyBandits.Policies.UCBVtuned.UCBVtuned|\l|__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"131" [label="{SMPyBandits.Policies.UCBalpha.UCBalpha|alpha : int\l|__init__(nbArms, alpha, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"132" [label="{SMPyBandits.Policies.UCBdagger.UCBdagger|alpha : int\lhorizon : int\l|__init__(nbArms, horizon, alpha, lower, amplitude)\l__str__()\lcomputeIndex(arm)\lgetReward(arm, reward)\l}", shape="record"];
"133" [label="{SMPyBandits.Policies.UCBimproved.UCBimproved|activeArms : list\lalpha : float\lcurrent_m : int\lestimate_delta : float, int\lhorizon : int\lmax_m : int\lmax_nb_of_exploration : int\lwhen_did_it_leave : ndarray\l|__init__(nbArms, horizon, alpha, lower, amplitude)\l__str__()\lchoice(recursive)\lcomputeIndex(arm)\lupdate_activeArms()\l}", shape="record"];
"134" [label="{SMPyBandits.Policies.UCBmin.UCBmin|\l|computeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"135" [label="{SMPyBandits.Policies.UCBoost.UCB_bq|c : float\l|__init__(nbArms, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"136" [label="{SMPyBandits.Policies.UCBoost.UCB_h|c : float\l|__init__(nbArms, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"137" [label="{SMPyBandits.Policies.UCBoost.UCB_lb|c : float\l|__init__(nbArms, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"138" [label="{SMPyBandits.Policies.UCBoost.UCB_sq|c : float\l|__init__(nbArms, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"139" [label="{SMPyBandits.Policies.UCBoost.UCB_t|c : float\l|__init__(nbArms, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"140" [label="{SMPyBandits.Policies.UCBoost.UCBoost|c : float\lset_D : NoneType, list, int\l|__init__(nbArms, set_D, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"141" [label="{SMPyBandits.Policies.UCBoost.UCBoostEpsilon|c : float\lepsilon : float\l|__init__(nbArms, epsilon, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"142" [label="{SMPyBandits.Policies.UCBoost.UCBoost_bq_h_lb|\l|__init__(nbArms, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"143" [label="{SMPyBandits.Policies.UCBoost.UCBoost_bq_h_lb_t|\l|__init__(nbArms, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"144" [label="{SMPyBandits.Policies.UCBoost.UCBoost_bq_h_lb_t_sq|\l|__init__(nbArms, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"145" [label="{SMPyBandits.Policies.UCBplus.UCBplus|\l|__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"146" [label="{SMPyBandits.Policies.UCBrandomInit.UCBrandomInit|_initial_exploration\l|__init__(nbArms, lower, amplitude)\lchoice()\l}", shape="record"];
"147" [label="{SMPyBandits.Policies.Uniform.Uniform|nbArms\l|__init__(nbArms, lower, amplitude)\l__str__()\lchoice()\lchoiceWithRank(rank)\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"148" [label="{SMPyBandits.Policies.UniformOnSome.UniformOnSome|armIndexes : NoneType, list\lnbArms\l|__init__(nbArms, armIndexes, lower, amplitude)\l__str__()\lchoice()\l}", shape="record"];
"149" [label="{SMPyBandits.Policies.WrapRange.WrapRange|_args : tuple\l_i : int\l_kwargs : dict\l_policy\lamplitude\lindex\llower\lpolicy : NoneType\lpulls\lrewards\lt\l|__init__(nbArms, policy, lower, amplitude)\l__str__()\lchoice()\lchoiceFromSubSet(availableArms)\lchoiceIMP(nb, startWithChoiceMultiple)\lchoiceMultiple(nb)\lchoiceWithRank(rank)\lcomputeAllIndex()\lcomputeIndex(arm)\lestimatedBestArms(M)\lestimatedOrder()\lgetReward(arm, reward)\lstartGame()\l}", shape="record"];
"150" [label="{SMPyBandits.Policies.klUCB.klUCB|c : float\lklucb\lklucb_vect : vectorize\ltolerance : float\l|__init__(nbArms, tolerance, klucb, c, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"151" [label="{SMPyBandits.Policies.klUCBH.klUCBH|horizon : int\l|__init__(nbArms, horizon, tolerance, klucb, c, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"152" [label="{SMPyBandits.Policies.klUCBHPlus.klUCBHPlus|horizon : int\l|__init__(nbArms, horizon, tolerance, klucb, c, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"153" [label="{SMPyBandits.Policies.klUCBPlus.klUCBPlus|\l|__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"154" [label="{SMPyBandits.Policies.klUCBPlusPlus.klUCBPlusPlus|horizon : int\lnbArms : float\l|__init__(nbArms, horizon, tolerance, klucb, c, lower, amplitude)\l__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"155" [label="{SMPyBandits.Policies.klUCB_forGLR.klUCB_forGLR|t_for_each_arm : ndarray\l|__init__(nbArms, tolerance, klucb, c, lower, amplitude)\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"156" [label="{SMPyBandits.Policies.klUCBloglog.klUCBloglog|\l|__str__()\lcomputeAllIndex()\lcomputeIndex(arm)\l}", shape="record"];
"157" [label="{SMPyBandits.Policies.klUCBswitch.klUCBswitch|_threshold_switch_name : str\lconstant_threshold_switch\lhorizon : NoneType\luse_MOSS_index : ndarray\l|__init__(nbArms, horizon, threshold, tolerance, klucb, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"158" [label="{SMPyBandits.Policies.klUCBswitch.klUCBswitchAnytime|_threshold_switch_name : str\lthreshold_switch : str\l|__init__(nbArms, threshold, tolerance, klucb, c, lower, amplitude)\l__str__()\lcomputeIndex(arm)\l}", shape="record"];
"0" -> "6" [arrowhead="empty", arrowtail="none"];
"1" -> "6" [arrowhead="empty", arrowtail="none"];
"2" -> "6" [arrowhead="empty", arrowtail="none"];
"3" -> "6" [arrowhead="empty", arrowtail="none"];
"4" -> "72" [arrowhead="empty", arrowtail="none"];
"5" -> "72" [arrowhead="empty", arrowtail="none"];
"7" -> "6" [arrowhead="empty", arrowtail="none"];
"8" -> "9" [arrowhead="empty", arrowtail="none"];
"9" -> "72" [arrowhead="empty", arrowtail="none"];
"10" -> "72" [arrowhead="empty", arrowtail="none"];
"11" -> "7" [arrowhead="empty", arrowtail="none"];
"12" -> "11" [arrowhead="empty", arrowtail="none"];
"13" -> "11" [arrowhead="empty", arrowtail="none"];
"14" -> "6" [arrowhead="empty", arrowtail="none"];
"15" -> "127" [arrowhead="empty", arrowtail="none"];
"16" -> "11" [arrowhead="empty", arrowtail="none"];
"17" -> "16" [arrowhead="empty", arrowtail="none"];
"18" -> "6" [arrowhead="empty", arrowtail="none"];
"19" -> "18" [arrowhead="empty", arrowtail="none"];
"20" -> "9" [arrowhead="empty", arrowtail="none"];
"21" -> "20" [arrowhead="empty", arrowtail="none"];
"22" -> "131" [arrowhead="empty", arrowtail="none"];
"23" -> "22" [arrowhead="empty", arrowtail="none"];
"24" -> "22" [arrowhead="empty", arrowtail="none"];
"25" -> "23" [arrowhead="empty", arrowtail="none"];
"25" -> "24" [arrowhead="empty", arrowtail="none"];
"26" -> "7" [arrowhead="empty", arrowtail="none"];
"27" -> "72" [arrowhead="empty", arrowtail="none"];
"28" -> "32" [arrowhead="empty", arrowtail="none"];
"29" -> "32" [arrowhead="empty", arrowtail="none"];
"30" -> "32" [arrowhead="empty", arrowtail="none"];
"31" -> "32" [arrowhead="empty", arrowtail="none"];
"32" -> "6" [arrowhead="empty", arrowtail="none"];
"33" -> "6" [arrowhead="empty", arrowtail="none"];
"34" -> "33" [arrowhead="empty", arrowtail="none"];
"35" -> "33" [arrowhead="empty", arrowtail="none"];
"36" -> "33" [arrowhead="empty", arrowtail="none"];
"37" -> "33" [arrowhead="empty", arrowtail="none"];
"38" -> "6" [arrowhead="empty", arrowtail="none"];
"39" -> "11" [arrowhead="empty", arrowtail="none"];
"40" -> "39" [arrowhead="empty", arrowtail="none"];
"41" -> "39" [arrowhead="empty", arrowtail="none"];
"42" -> "33" [arrowhead="empty", arrowtail="none"];
"43" -> "6" [arrowhead="empty", arrowtail="none"];
"44" -> "49" [arrowhead="empty", arrowtail="none"];
"45" -> "32" [arrowhead="empty", arrowtail="none"];
"46" -> "32" [arrowhead="empty", arrowtail="none"];
"47" -> "32" [arrowhead="empty", arrowtail="none"];
"48" -> "49" [arrowhead="empty", arrowtail="none"];
"49" -> "32" [arrowhead="empty", arrowtail="none"];
"50" -> "6" [arrowhead="empty", arrowtail="none"];
"51" -> "50" [arrowhead="empty", arrowtail="none"];
"52" -> "55" [arrowhead="empty", arrowtail="none"];
"53" -> "52" [arrowhead="empty", arrowtail="none"];
"53" -> "56" [arrowhead="empty", arrowtail="none"];
"54" -> "52" [arrowhead="empty", arrowtail="none"];
"54" -> "57" [arrowhead="empty", arrowtail="none"];
"55" -> "11" [arrowhead="empty", arrowtail="none"];
"56" -> "55" [arrowhead="empty", arrowtail="none"];
"57" -> "55" [arrowhead="empty", arrowtail="none"];
"58" -> "55" [arrowhead="empty", arrowtail="none"];
"59" -> "56" [arrowhead="empty", arrowtail="none"];
"59" -> "58" [arrowhead="empty", arrowtail="none"];
"60" -> "57" [arrowhead="empty", arrowtail="none"];
"60" -> "58" [arrowhead="empty", arrowtail="none"];
"61" -> "55" [arrowhead="empty", arrowtail="none"];
"62" -> "56" [arrowhead="empty", arrowtail="none"];
"62" -> "61" [arrowhead="empty", arrowtail="none"];
"63" -> "57" [arrowhead="empty", arrowtail="none"];
"63" -> "61" [arrowhead="empty", arrowtail="none"];
"64" -> "11" [arrowhead="empty", arrowtail="none"];
"65" -> "6" [arrowhead="empty", arrowtail="none"];
"66" -> "72" [arrowhead="empty", arrowtail="none"];
"67" -> "72" [arrowhead="empty", arrowtail="none"];
"68" -> "6" [arrowhead="empty", arrowtail="none"];
"69" -> "68" [arrowhead="empty", arrowtail="none"];
"70" -> "68" [arrowhead="empty", arrowtail="none"];
"71" -> "18" [arrowhead="empty", arrowtail="none"];
"72" -> "6" [arrowhead="empty", arrowtail="none"];
"73" -> "6" [arrowhead="empty", arrowtail="none"];
"74" -> "6" [arrowhead="empty", arrowtail="none"];
"75" -> "6" [arrowhead="empty", arrowtail="none"];
"76" -> "72" [arrowhead="empty", arrowtail="none"];
"77" -> "76" [arrowhead="empty", arrowtail="none"];
"78" -> "76" [arrowhead="empty", arrowtail="none"];
"79" -> "76" [arrowhead="empty", arrowtail="none"];
"80" -> "7" [arrowhead="empty", arrowtail="none"];
"81" -> "6" [arrowhead="empty", arrowtail="none"];
"82" -> "6" [arrowhead="empty", arrowtail="none"];
"83" -> "127" [arrowhead="empty", arrowtail="none"];
"84" -> "85" [arrowhead="empty", arrowtail="none"];
"85" -> "83" [arrowhead="empty", arrowtail="none"];
"86" -> "87" [arrowhead="empty", arrowtail="none"];
"87" -> "6" [arrowhead="empty", arrowtail="none"];
"88" -> "87" [arrowhead="empty", arrowtail="none"];
"89" -> "87" [arrowhead="empty", arrowtail="none"];
"90" -> "87" [arrowhead="empty", arrowtail="none"];
"91" -> "7" [arrowhead="empty", arrowtail="none"];
"92" -> "72" [arrowhead="empty", arrowtail="none"];
"93" -> "6" [arrowhead="empty", arrowtail="none"];
"94" -> "50" [arrowhead="empty", arrowtail="none"];
"95" -> "94" [arrowhead="empty", arrowtail="none"];
"96" -> "94" [arrowhead="empty", arrowtail="none"];
"97" -> "94" [arrowhead="empty", arrowtail="none"];
"98" -> "99" [arrowhead="empty", arrowtail="none"];
"98" -> "131" [arrowhead="empty", arrowtail="none"];
"99" -> "72" [arrowhead="empty", arrowtail="none"];
"100" -> "6" [arrowhead="empty", arrowtail="none"];
"101" -> "100" [arrowhead="empty", arrowtail="none"];
"102" -> "100" [arrowhead="empty", arrowtail="none"];
"103" -> "72" [arrowhead="empty", arrowtail="none"];
"104" -> "103" [arrowhead="empty", arrowtail="none"];
"105" -> "7" [arrowhead="empty", arrowtail="none"];
"106" -> "127" [arrowhead="empty", arrowtail="none"];
"107" -> "131" [arrowhead="empty", arrowtail="none"];
"108" -> "150" [arrowhead="empty", arrowtail="none"];
"109" -> "7" [arrowhead="empty", arrowtail="none"];
"110" -> "72" [arrowhead="empty", arrowtail="none"];
"111" -> "110" [arrowhead="empty", arrowtail="none"];
"112" -> "110" [arrowhead="empty", arrowtail="none"];
"113" -> "111" [arrowhead="empty", arrowtail="none"];
"113" -> "112" [arrowhead="empty", arrowtail="none"];
"114" -> "115" [arrowhead="empty", arrowtail="none"];
"115" -> "6" [arrowhead="empty", arrowtail="none"];
"116" -> "115" [arrowhead="empty", arrowtail="none"];
"117" -> "115" [arrowhead="empty", arrowtail="none"];
"118" -> "131" [arrowhead="empty", arrowtail="none"];
"119" -> "7" [arrowhead="empty", arrowtail="none"];
"120" -> "150" [arrowhead="empty", arrowtail="none"];
"121" -> "72" [arrowhead="empty", arrowtail="none"];
"122" -> "6" [arrowhead="empty", arrowtail="none"];
"123" -> "122" [arrowhead="empty", arrowtail="none"];
"124" -> "9" [arrowhead="empty", arrowtail="none"];
"125" -> "6" [arrowhead="empty", arrowtail="none"];
"126" -> "33" [arrowhead="empty", arrowtail="none"];
"127" -> "72" [arrowhead="empty", arrowtail="none"];
"128" -> "131" [arrowhead="empty", arrowtail="none"];
"129" -> "127" [arrowhead="empty", arrowtail="none"];
"130" -> "129" [arrowhead="empty", arrowtail="none"];
"131" -> "127" [arrowhead="empty", arrowtail="none"];
"132" -> "72" [arrowhead="empty", arrowtail="none"];
"133" -> "121" [arrowhead="empty", arrowtail="none"];
"134" -> "127" [arrowhead="empty", arrowtail="none"];
"135" -> "72" [arrowhead="empty", arrowtail="none"];
"136" -> "72" [arrowhead="empty", arrowtail="none"];
"137" -> "72" [arrowhead="empty", arrowtail="none"];
"138" -> "72" [arrowhead="empty", arrowtail="none"];
"139" -> "72" [arrowhead="empty", arrowtail="none"];
"140" -> "72" [arrowhead="empty", arrowtail="none"];
"141" -> "72" [arrowhead="empty", arrowtail="none"];
"142" -> "140" [arrowhead="empty", arrowtail="none"];
"143" -> "140" [arrowhead="empty", arrowtail="none"];
"144" -> "140" [arrowhead="empty", arrowtail="none"];
"145" -> "127" [arrowhead="empty", arrowtail="none"];
"146" -> "127" [arrowhead="empty", arrowtail="none"];
"147" -> "6" [arrowhead="empty", arrowtail="none"];
"148" -> "147" [arrowhead="empty", arrowtail="none"];
"149" -> "6" [arrowhead="empty", arrowtail="none"];
"150" -> "72" [arrowhead="empty", arrowtail="none"];
"151" -> "150" [arrowhead="empty", arrowtail="none"];
"152" -> "150" [arrowhead="empty", arrowtail="none"];
"153" -> "150" [arrowhead="empty", arrowtail="none"];
"154" -> "150" [arrowhead="empty", arrowtail="none"];
"155" -> "156" [arrowhead="empty", arrowtail="none"];
"156" -> "150" [arrowhead="empty", arrowtail="none"];
"157" -> "150" [arrowhead="empty", arrowtail="none"];
"158" -> "157" [arrowhead="empty", arrowtail="none"];
"127" -> "7" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_policy", style="solid"];
"127" -> "7" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="policy", style="solid"];
"127" -> "26" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="policy", style="solid"];
"127" -> "26" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="policy", style="solid"];
"127" -> "26" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="policy", style="solid"];
"127" -> "26" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="policy", style="solid"];
"127" -> "149" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_policy", style="solid"];
"127" -> "149" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="policy", style="solid"];
}
