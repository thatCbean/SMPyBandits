digraph "classes_SMPyBandits.Environment" {
charset="utf-8"
rankdir=BT
"0" [label="{SMPyBandits.Environment.Evaluator.Evaluator|_times\lallPulls : dict\lallRewards : ndarray\lappend_labels\laverageOn : float\lbestArmPulls : dict\lcache_rewards\lcfg\lchange_labels\ldelta_t_plot : int\lenvironment_bayesian\lenvs : list\lfinalRanksOnAverage : bool\lhorizon\llastCumRewards : ndarray\llastPulls : dict\lmaxCumRewards\lmemoryConsumption : dict\lminCumRewards\lmoreAccurate : bool\lnbPolicies\lnb_break_points\lnumberOfCPDetections : dict\lplot_lowerbound\lpolicies : list\lpulls : dict\lrandom_invert\lrandom_shuffle\lrepetitions\lrewards : ndarray\lrewardsSquared : ndarray\lrunningTimes : dict\lshowplot\lsignature : str\luseJoblib\luseJoblibForPolicies : bool\luse_box_plot\l|__initEnvironments__()\l__initPolicies__(env)\l__init__(configuration, finalRanksOnAverage, averageOn, useJoblibForPolicies, moreAccurate)\l_xlabel(envId)\lcompute_cache_rewards(arms)\lgetAllLastWeightedSelections(policyId, envId)\lgetAverageRewards(policyId, envId)\lgetAverageWeightedSelections(policyId, envId)\lgetBestArmPulls(policyId, envId)\lgetCumulatedRegret(policyId, envId, moreAccurate)\lgetCumulatedRegret_LessAccurate(policyId, envId)\lgetCumulatedRegret_MoreAccurate(policyId, envId)\lgetLastRegrets(policyId, envId, moreAccurate)\lgetLastRegrets_LessAccurate(policyId, envId)\lgetLastRegrets_MoreAccurate(policyId, envId)\lgetMaxMinReward(policyId, envId)\lgetMaxRewards(envId)\lgetMemoryConsumption(envId)\lgetNumberOfCPDetections(envId)\lgetPulls(policyId, envId)\lgetRewards(policyId, envId)\lgetRewardsSquared(policyId, envId)\lgetRunningTimes(envId)\lgetSTDRegret(policyId, envId, meanReward)\lplotBestArmPulls(envId, savefig)\lplotHistoryOfMeans(envId, horizon, savefig)\lplotLastRegrets(envId, normed, subplots, nbbins, log, all_on_separate_figures, sharex, sharey, boxplot, normalized_boxplot, savefig, moreAccurate)\lplotMemoryConsumption(envId, savefig, base, unit)\lplotNumberOfCPDetections(envId, savefig)\lplotRegrets(envId, savefig, meanReward, plotSTD, plotMaxMin, semilogx, semilogy, loglog, normalizedRegret, drawUpperBound, moreAccurate)\lplotRunningTimes(envId, savefig, base, unit)\lprintFinalRanking(envId, moreAccurate)\lprintLastRegrets(envId, moreAccurate)\lprintMemoryConsumption(envId)\lprintNumberOfCPDetections(envId)\lprintRunningTimes(envId, precision)\lsaveondisk(filepath)\lstartAllEnv()\lstartOneEnv(envId, env)\l}", shape="record"];
"1" [label="{SMPyBandits.Environment.EvaluatorMultiPlayers.EvaluatorMultiPlayers|_times\lallPulls : dict\lappend_labels\laverageOn\lbestArmPulls : dict\lcfg\lchange_labels\lcollisionModel\lcollisions : dict\lcount_ranks_markov_chain\ldelta_t_plot : int\lenvs : list\lfinalRanksOnAverage\lfreeTransmissions : dict\lfull_lost_if_collision\lhorizon : int\llastCumCollisions : dict\llastCumRewards : dict\llastPulls : dict\lmemoryConsumption : dict\lmoreAccurate : bool\lnbPlayers\lnbSwitchs : dict\lnb_break_points\lplayers : list\lplot_lowerbounds\lpulls : dict\lrepetitions\lrewards : dict\lrunningTimes : dict\lshowplot\lsignature : str\luseJoblib\luse_box_plot\l|__initEnvironments__()\l__initPlayers__(env)\l__init__(configuration, moreAccurate)\lgetAllLastWeightedSelections(envId)\lgetAllPulls(playerId, armId, envId)\lgetBestArmPulls(playerId, envId)\lgetCentralizedNbSwitchs(envId)\lgetCentralizedRegret(envId, moreAccurate)\lgetCentralizedRegret_LessAccurate(envId)\lgetCentralizedRegret_MoreAccurate(envId)\lgetCollisions(armId, envId)\lgetFirstRegretTerm(envId)\lgetLastRegrets(envId, moreAccurate)\lgetLastRegrets_LessAccurate(envId)\lgetLastRegrets_MoreAccurate(envId)\lgetMemoryConsumption(envId)\lgetNbSwitchs(playerId, envId)\lgetPulls(playerId, envId)\lgetRegretMean(playerId, envId)\lgetRewards(playerId, envId)\lgetRunningTimes(envId)\lgetSecondRegretTerm(envId)\lgetThirdRegretTerm(envId)\lgetfreeTransmissions(playerId, envId)\lloadfromdisk(filepath)\lplotAllPulls(envId, savefig, cumulated, normalized)\lplotBestArmPulls(envId, savefig)\lplotFairness(envId, savefig, semilogx, fairness, evaluators)\lplotFreeTransmissions(envId, savefig, cumulated)\lplotFrequencyCollisions(envId, savefig, piechart, semilogy)\lplotHistoryOfMeans(envId, horizon, savefig)\lplotLastRegrets(envId, normed, subplots, nbbins, log, all_on_separate_figures, sharex, sharey, boxplot, normalized_boxplot, savefig, moreAccurate, evaluators)\lplotMemoryConsumption(envId, savefig, base, unit, evaluators)\lplotNbCollisions(envId, savefig, semilogx, semilogy, loglog, cumulated, upperbound, evaluators)\lplotNbSwitchs(envId, savefig, semilogx, cumulated)\lplotNbSwitchsCentralized(envId, savefig, semilogx, cumulated, evaluators)\lplotRegretCentralized(envId, savefig, semilogx, semilogy, loglog, normalized, evaluators, subTerms, sumofthreeterms, moreAccurate)\lplotRewards(envId, savefig, semilogx, moreAccurate)\lplotRunningTimes(envId, savefig, base, unit, evaluators)\lprintFinalRanking(envId, verb)\lprintFinalRankingAll(envId, evaluators)\lprintLastRegrets(envId, evaluators, moreAccurate)\lprintLastRegretsPM(envId, evaluators, moreAccurate)\lprintMemoryConsumption(envId, evaluators)\lprintRunningTimes(envId, precision, evaluators)\lsaveondisk(filepath)\lstartAllEnv()\lstartOneEnv(envId, env)\lstrPlayers(short, latex)\l}", shape="record"];
"2" [label="{SMPyBandits.Environment.EvaluatorSparseMultiPlayers.EvaluatorSparseMultiPlayers|activations\lcollisionModel\lfull_lost_if_collision\lplayers : list\l|__init__(configuration, moreAccurate)\lgetAllLastWeightedSelections(envId)\lgetCentralizedRegret(envId, moreAccurate)\lgetCentralizedRegret_LessAccurate(envId)\lgetCentralizedRegret_MoreAccurate(envId)\lgetFirstRegretTerm(envId)\lgetLastRegrets(envId, moreAccurate)\lgetLastRegrets_LessAccurate(envId)\lgetLastRegrets_MoreAccurate(envId)\lgetSecondRegretTerm(envId)\lgetThirdRegretTerm(envId)\lstartOneEnv(envId, env)\lstrPlayers(short, latex)\l}", shape="record"];
"3" [label="{SMPyBandits.Environment.MAB.ChangingAtEachRepMAB|_arms\l_historyOfMeans : list\l_sparsity : NoneType\l_t : int\l_verbose : bool\largs\larm_type\larms\lisChangingAtEachRepetition : bool\lisDynamic : bool\lisMarkovian : bool\lmaxArm\lmeans\lminArm\lnbArms\lnewMeans\l|Mbest(M)\lMworst(M)\l__init__(configuration, verbose)\l__repr__()\lhoifactor()\llowerbound()\llowerbound_multiplayers(nbPlayers)\lnewRandomArms(t, verbose)\lreprarms(nbPlayers, openTag, endTag, latex)\l}", shape="record"];
"4" [label="{SMPyBandits.Environment.MAB.IncreasingMAB|_amplitudes : ndarray\l_change_lower_amplitude\l_first_amplitudes : ndarray\l_first_lowers : ndarray\l_lowers : ndarray\lisDynamic : bool\l|__init__(configuration)\ldraw(armId, t)\l}", shape="record"];
"5" [label="{SMPyBandits.Environment.MAB.MAB|_sparsity : NoneType\larms : list\lisChangingAtEachRepetition : bool\lisDynamic : bool\lisMarkovian : bool\lmaxArm\lmeans : ndarray\lminArm\lnbArms\lsparsity\l|Mbest(M)\lMworst(M)\l__init__(configuration)\l__repr__()\ldraw(armId, t)\ldraw_each(t)\ldraw_each_nparray(shape)\ldraw_nparray(armId, shape)\lget_allMeans(horizon)\lget_maxArm(horizon)\lget_maxArms(M, horizon)\lget_minArm(horizon)\lhoifactor()\llowerbound()\llowerbound_multiplayers(nbPlayers)\llowerbound_sparse(sparsity)\lnew_order_of_arm(arms)\lplotComparison_our_anandkumar(savefig)\lplotHistogram(horizon, savefig, bins, alpha, density)\lreprarms(nbPlayers, openTag, endTag, latex)\lstr_sparsity()\lsumBestMeans(M)\lupperbound_collisions(nbPlayers, times)\l}", shape="record"];
"6" [label="{SMPyBandits.Environment.MAB.MarkovianMAB|_sparsity : NoneType\larms\lchains\ldict_transitions : list\lisChangingAtEachRepetition : bool\lisDynamic : bool\lisMarkovian : bool\lmatrix_transitions : list\lmaxArm\lmeans : ndarray\lminArm\lnbArms : int\lrested\lstates : ndarray\lsteadys\l|__init__(configuration)\l__repr__()\ldraw(armId, t)\lreprarms(nbPlayers, openTag, endTag, latex)\l}", shape="record"];
"7" [label="{SMPyBandits.Environment.MAB.NonStationaryMAB|_arms\l_historyOfChangePoints : list\l_historyOfMeans : dict\l_sparsity : NoneType\l_t : int\l_verbose : bool\largs\larm_type\lchangePoints\lisChangingAtEachRepetition : bool\lisDynamic : bool\lisMarkovian : bool\lnbArms\lnewMeans\lonlyOneArm\l|__init__(configuration, verbose)\lget_allMeans(horizon)\lget_maxArm(horizon)\lget_minArm(horizon)\lnewRandomArms(t, onlyOneArm, verbose)\lreprarms(nbPlayers, openTag, endTag, latex)\l}", shape="record"];
"8" [label="{SMPyBandits.Environment.MAB.PieceWiseStationaryMAB|_sparsity : NoneType\l_verbose : bool\larm_type\larms\lchangePoints\lcurrentInterval : int\lisChangingAtEachRepetition : bool\lisDynamic : bool\lisMarkovian : bool\llistOfArms\llistOfMeans : ndarray\lmaxArm\lmeans\lminArm\lnbArms\l|__init__(configuration, verbose)\l__repr__()\lget_allMeans(horizon)\lget_maxArm(horizon)\lget_maxArms(M, horizon)\lget_minArm(horizon)\lget_minArms(M, horizon)\lnewRandomArms(t, onlyOneArm, verbose)\lplotHistoryOfMeans(horizon, savefig, forceTo01, showplot, pickleit)\lreprarms(nbPlayers, openTag, endTag, latex)\l}", shape="record"];
"9" [label="{SMPyBandits.Environment.Result.Result|choices : ndarray\lindexes_bestarm\lmemory_consumption : int\lnumber_of_cp_detections : int\lpulls : ndarray\lrewards : ndarray\lrunning_time : int\l|__init__(nbArms, horizon, indexes_bestarm, means)\lchange_in_arms(time, indexes_bestarm)\lstore(time, choice, reward)\l}", shape="record"];
"10" [label="{SMPyBandits.Environment.ResultMultiPlayers.ResultMultiPlayers|allPulls : ndarray\lchoices : ndarray\lcollisions : ndarray\lmemory_consumption : int\lpulls : ndarray\lrewards : ndarray\lrunning_time : int\l|__init__(nbArms, horizon, nbPlayers, means)\lstore(time, choices, rewards, pulls, collisions)\l}", shape="record"];
"11" [label="{SMPyBandits.Environment.pykov.Chain|_fundamental_matrix\l_guess\l_steady\l|absorbing_time(transient_set)\labsorbing_tour(p, transient_set)\laccessibility_matrix()\ladjacency()\lcommunicates(i, j)\lcommunication_classes()\lentropy(p, norm)\lfundamental_matrix()\lis_accessible(i, j)\lkemeny_constant()\lmfpt_to(state)\lmixing_time(cutoff, jump, p)\lmove(state, random_func)\lpow(p, n)\lsteady()\lwalk(steps, start, stop)\lwalk_probability(walk)\l}", shape="record"];
"12" [label="{SMPyBandits.Environment.pykov.Matrix|_pred : OrderedDict\l_states : set\l_succ : OrderedDict\l|_UMPFPACKSolve(b, x, method)\l__add__(M)\l__delitem__(key)\l__getitem__()\l__init__(data)\l__mul__(v)\l__pow__(n)\l__reduce__()\l__rmul__(v)\l__setitem__(key, value)\l__sub__(M)\l_dok_(el2pos, method)\l_el2pos_()\l_from_dok_(mat, pos2el)\l_from_numpy_mat(T, pos2el)\l_numpy_mat(el2pos)\lclear()\lcopy()\leye()\lones()\lpop(key)\lpopitem()\lpow(n)\lpred(key)\lremove(states)\lsetdefault(k)\lstates()\lstochastic()\lsucc(key)\ltrace()\ltranspose()\lupdate(other)\l}", shape="record"];
"13" [fontcolor="red", label="{SMPyBandits.Environment.pykov.PykovError|value\l|__init__(value)\l__str__()\l}", shape="record"];
"14" [label="{SMPyBandits.Environment.pykov.Vector|\l|__add__(v)\l__getitem__(key)\l__init__(data)\l__mul__(M)\l__rmul__(M)\l__setitem__(key, value)\l__sub__(v)\l_fromarray(arr, el2pos)\l_toarray(el2pos)\lchoose(random_func)\lcopy()\ldist(v)\lentropy()\lnormalize()\lrelative_entropy(p)\lsort(reverse)\lsum()\l}", shape="record"];
"2" -> "1" [arrowhead="empty", arrowtail="none"];
"3" -> "5" [arrowhead="empty", arrowtail="none"];
"4" -> "5" [arrowhead="empty", arrowtail="none"];
"6" -> "5" [arrowhead="empty", arrowtail="none"];
"7" -> "8" [arrowhead="empty", arrowtail="none"];
"8" -> "5" [arrowhead="empty", arrowtail="none"];
"11" -> "12" [arrowhead="empty", arrowtail="none"];
"12" -> "11" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_fundamental_matrix", style="solid"];
"14" -> "11" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_steady", style="solid"];
"14" -> "11" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_guess", style="solid"];
}
